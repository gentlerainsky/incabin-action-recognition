{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from modules.pose_extractor.pose2d_estimator.pose2d_estimator import Pose2DEstimator\n",
    "from modules.pose_extractor.pose2d_estimator.pose2d_extractor import Pose2DExtractor\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_udp-8xb32-210e_coco-384x288-70d7ab01_20220913.pth\n",
      "04/16 16:45:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmpose\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmpose\" is a correct scope, or whether the registry is initialized.\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\n",
      "04/16 16:45:06 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n"
     ]
    }
   ],
   "source": [
    "video_root = Path('/root/data/raw/drive_and_act/')\n",
    "video_path = video_root / 'inner_mirror' / 'vp1' / 'run1b_2018-05-29-14-02-47.ids_1.mp4'\n",
    "annotation_path = video_root / 'iccv_activities_3s' / 'activities_3s' / 'inner_mirror' / 'midlevel.chunks_90.split_0.train.csv'\n",
    "# annotation_path = video_root / 'iccv_activities_3s' / 'activities_3s' / 'inner_mirror' / 'midlevel.chunks_90.csv'\n",
    "pose_estimator_2d = Pose2DEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75% | Time used = 00:04:30\n",
      "1.51% | Time used = 00:09:22\n",
      "2.26% | Time used = 00:14:17\n",
      "3.01% | Time used = 00:19:10\n",
      "3.76% | Time used = 00:23:34\n",
      "4.52% | Time used = 00:28:08\n",
      "5.27% | Time used = 00:32:31\n",
      "6.02% | Time used = 00:36:34\n",
      "6.78% | Time used = 00:41:30\n",
      "7.53% | Time used = 00:45:58\n",
      "8.28% | Time used = 00:50:15\n",
      "9.03% | Time used = 00:55:04\n",
      "9.79% | Time used = 00:59:32\n",
      "10.54% | Time used = 01:04:46\n",
      "11.29% | Time used = 01:09:08\n",
      "12.04% | Time used = 01:13:28\n",
      "12.80% | Time used = 01:18:08\n",
      "13.55% | Time used = 01:22:23\n",
      "14.30% | Time used = 01:27:08\n",
      "15.06% | Time used = 01:31:50\n",
      "15.81% | Time used = 01:36:26\n",
      "16.56% | Time used = 01:41:18\n",
      "17.31% | Time used = 01:46:14\n",
      "18.07% | Time used = 01:50:42\n",
      "18.82% | Time used = 01:55:16\n",
      "19.57% | Time used = 01:59:47\n",
      "20.33% | Time used = 02:04:25\n",
      "21.08% | Time used = 02:08:26\n",
      "21.83% | Time used = 02:13:06\n",
      "22.58% | Time used = 02:17:53\n",
      "23.34% | Time used = 02:22:33\n",
      "24.09% | Time used = 02:27:12\n",
      "24.84% | Time used = 02:31:43\n",
      "25.59% | Time used = 02:35:09\n",
      "26.35% | Time used = 02:40:30\n",
      "27.10% | Time used = 02:45:13\n",
      "27.85% | Time used = 02:50:23\n",
      "28.61% | Time used = 02:55:41\n",
      "29.36% | Time used = 03:00:32\n",
      "30.11% | Time used = 03:04:20\n",
      "30.86% | Time used = 03:08:56\n",
      "31.62% | Time used = 03:13:20\n",
      "32.37% | Time used = 03:18:51\n",
      "33.12% | Time used = 03:23:34\n",
      "33.88% | Time used = 03:28:22\n",
      "34.63% | Time used = 03:33:19\n",
      "35.38% | Time used = 03:37:38\n",
      "36.13% | Time used = 03:42:28\n",
      "36.89% | Time used = 03:48:00\n",
      "37.64% | Time used = 03:53:21\n",
      "38.39% | Time used = 03:57:58\n",
      "39.14% | Time used = 04:03:24\n",
      "39.90% | Time used = 04:08:42\n",
      "40.65% | Time used = 04:13:44\n",
      "41.40% | Time used = 04:18:31\n",
      "42.16% | Time used = 04:23:42\n",
      "42.91% | Time used = 04:28:34\n",
      "43.66% | Time used = 04:33:26\n",
      "44.41% | Time used = 04:38:21\n",
      "45.17% | Time used = 04:43:41\n",
      "45.92% | Time used = 04:49:00\n",
      "46.67% | Time used = 04:54:16\n",
      "47.43% | Time used = 04:59:49\n",
      "48.18% | Time used = 05:05:12\n",
      "48.93% | Time used = 05:10:40\n",
      "49.68% | Time used = 05:16:16\n",
      "50.44% | Time used = 05:21:07\n",
      "51.19% | Time used = 05:26:23\n",
      "51.94% | Time used = 05:31:41\n",
      "52.69% | Time used = 05:37:31\n",
      "53.45% | Time used = 05:42:53\n",
      "54.20% | Time used = 05:48:11\n",
      "54.95% | Time used = 05:53:33\n",
      "55.71% | Time used = 05:58:50\n",
      "56.46% | Time used = 06:04:16\n",
      "57.21% | Time used = 06:10:19\n",
      "57.96% | Time used = 06:15:60\n",
      "58.72% | Time used = 06:21:51\n",
      "59.47% | Time used = 06:27:13\n",
      "60.22% | Time used = 06:32:03\n",
      "60.98% | Time used = 06:37:30\n",
      "61.73% | Time used = 06:42:55\n",
      "62.48% | Time used = 06:47:57\n",
      "63.23% | Time used = 06:52:58\n",
      "63.99% | Time used = 06:57:49\n",
      "64.74% | Time used = 07:03:32\n",
      "65.49% | Time used = 07:09:34\n",
      "66.25% | Time used = 07:15:13\n",
      "67.00% | Time used = 07:20:47\n",
      "67.75% | Time used = 07:26:42\n",
      "68.50% | Time used = 07:32:38\n",
      "69.26% | Time used = 07:38:44\n",
      "70.01% | Time used = 07:44:11\n",
      "70.76% | Time used = 07:49:43\n",
      "71.51% | Time used = 07:55:37\n",
      "72.27% | Time used = 08:01:42\n",
      "73.02% | Time used = 08:07:32\n",
      "73.77% | Time used = 08:12:42\n",
      "74.53% | Time used = 08:18:55\n",
      "75.28% | Time used = 08:24:21\n",
      "76.03% | Time used = 08:29:55\n",
      "76.78% | Time used = 08:36:04\n",
      "77.54% | Time used = 08:41:41\n",
      "78.29% | Time used = 08:47:52\n",
      "79.04% | Time used = 08:53:48\n",
      "79.80% | Time used = 08:59:22\n",
      "80.55% | Time used = 09:05:35\n",
      "81.30% | Time used = 09:11:56\n",
      "82.05% | Time used = 09:17:24\n",
      "82.81% | Time used = 09:23:18\n",
      "83.56% | Time used = 09:29:08\n",
      "84.31% | Time used = 09:34:05\n",
      "85.06% | Time used = 09:40:03\n",
      "85.82% | Time used = 09:45:24\n",
      "86.57% | Time used = 09:51:26\n",
      "87.32% | Time used = 09:57:32\n",
      "88.08% | Time used = 10:03:09\n",
      "88.83% | Time used = 10:08:33\n",
      "89.58% | Time used = 10:14:56\n",
      "90.33% | Time used = 10:21:08\n",
      "91.09% | Time used = 10:27:24\n",
      "91.84% | Time used = 10:33:47\n",
      "92.59% | Time used = 10:40:43\n",
      "93.35% | Time used = 10:47:32\n",
      "94.10% | Time used = 10:53:26\n",
      "94.85% | Time used = 10:59:52\n",
      "95.60% | Time used = 11:06:02\n",
      "96.36% | Time used = 11:11:57\n",
      "97.11% | Time used = 11:19:24\n",
      "97.86% | Time used = 11:26:01\n",
      "98.61% | Time used = 11:32:36\n",
      "99.37% | Time used = 11:39:21\n"
     ]
    }
   ],
   "source": [
    "extractor = Pose2DExtractor(\n",
    "    video_root_path=video_root.as_posix(),\n",
    "    data_subset='train',\n",
    "    pose_estimator_2d=pose_estimator_2d,\n",
    "    pickle_output_path='./output'\n",
    ")\n",
    "extractor.extract_2d_pose_from_annotation_file(annotation_path.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df = pd.read_csv(str(annotation_path))\n",
    "# # with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "# #     display(df[df['participant_id'] == 1])\n",
    "# df = df.set_index(['participant_id', 'file_id'])\n",
    "\n",
    "# frame_info = []\n",
    "# pose_2d_results = []\n",
    "# current_video_name = None\n",
    "# num_rows = df.shape[0]\n",
    "# frame_count = 0\n",
    "# annotation_count = 0\n",
    "# for index, row in df.iterrows():\n",
    "#     if (count + 1) % 100 == 0:\n",
    "#         print(f'{((index + 1) / num_rows * 100):.2f}%')\n",
    "#     annotation_count += 1\n",
    "#     participant_id, video_name = index\n",
    "#     if current_video_name != video_name:\n",
    "#         video_file = str(video_path)\n",
    "#         cap = cv2.VideoCapture(video_file)\n",
    "#         total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#         frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "#         # in Hz\n",
    "#         sampling_rate = 15\n",
    "#         sampling_rate = int((1 / sampling_rate) * np.floor(frame_rate))\n",
    "#     images = []\n",
    "#     start = row['frame_start']\n",
    "#     end = row['frame_end']\n",
    "#     for frame_number in range(start, end, sampling_rate):\n",
    "#         cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "#         _, image = cap.read()\n",
    "#         images.append(image)\n",
    "#     bboxes, pose_2d_list, keypoint_2d_scores = pose_estimator_2d.inference(images)\n",
    "#     for idx, image in enumerate(images):\n",
    "#         frame_info.append(dict(\n",
    "#             frame_index=annotation_count,\n",
    "#             participant_id=participant_id,\n",
    "#             video_name=video_name,\n",
    "#             annotation_id=row['annotation_id'],\n",
    "#             frame=start + idx,\n",
    "#             activity=row['activity'],\n",
    "#         ))\n",
    "#         pose_2d_results.append(dict(\n",
    "#             frame_index=annotation_count,\n",
    "#             pose_2d=pose_2d_list[idx],\n",
    "#             pose_2d_score=keypoint_2d_scores[idx],\n",
    "#             pose_2d_avg_score=np.mean(keypoint_2d_scores[idx])\n",
    "#         ))\n",
    "#         frame_count += 1\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose_2d_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(images[10])\n",
    "# ax.scatter(pose_2d_list[10][:, 0], pose_2d_list[10][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mmpose.apis import MMPoseInferencer\n",
    "\n",
    "# # img_path = 'tests/data/coco/000000000785.jpg'   # replace this with your own image path\n",
    "\n",
    "# # instantiate the inferencer using the model alias\n",
    "# inferencer = MMPoseInferencer('td-hm_ViTPose-large-simple_8xb64-210e_coco-256x192')\n",
    "\n",
    "# # The MMPoseInferencer API employs a lazy inference approach,\n",
    "# # creating a prediction generator when given input\n",
    "# result_generator = inferencer(images[0], show=True)\n",
    "# result = next(result_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
